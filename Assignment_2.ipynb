{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_2.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMIoDu6KgO0Fmhst0IIAXIu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngzhankang/Deep-Learning/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "785x_a6G9Zjb"
      },
      "source": [
        "# Assignment 2 - Part A\r\n",
        "Done by : \r\n",
        "- P1935727 Ng Zhan Kang\r\n",
        "- P1935488 Triston Loh\r\n",
        "\r\n",
        "Class of DIT/FT/2B/11"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWPr2yoR9b1L"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ6B_Ox-9dk9"
      },
      "source": [
        "### 1.1 Ensuring 0% Util\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Ensure that our slot give by Google is not utilized yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynsgiEvY9hYt"
      },
      "source": [
        "# to ensure that the current gpu utilization is 0\r\n",
        "# memory footprint support libraries/code\r\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\r\n",
        "!pip install gputil\r\n",
        "!pip install psutil\r\n",
        "!pip install humanize\r\n",
        "import psutil\r\n",
        "import humanize\r\n",
        "\r\n",
        "import os\r\n",
        "import GPUtil as GPU\r\n",
        "GPUs = GPU.getGPUs()\r\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\r\n",
        "gpu = GPUs[0]\r\n",
        "def printm():\r\n",
        " process = psutil.Process(os.getpid())\r\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\r\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\r\n",
        "printm() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGOd1eqy9jKo"
      },
      "source": [
        "### 1.2. Forcing Utils To 0% To Get A Clean Cluster\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "Please do not use this step unless the cluster you are allocated to is quite full."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_Bdj5jp9j5M"
      },
      "source": [
        "## if utilization is > 0, run this code(keep running this cell and the above cell till the util number is 0%):\r\n",
        "## NOTE THAT RUNNING THIS MIGHT KILL GPU SESSION AND RESULT IN DATA LOSS(NOT ADVICABLE TO KEEP ON REUSING)\r\n",
        "# !kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAaNe09e9oLR"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQj374_o9sLf"
      },
      "source": [
        "# 2.Ensuring GPU Is Utilized In Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_TDC8qN9ua2"
      },
      "source": [
        "### 2.1. See the list of available devices\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "This entire section can be omitted if users are not utilizing GPU at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1tD0OGV9w2Y"
      },
      "source": [
        "from tensorflow.python.client import device_lib\r\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Ve52Ro9zxP"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujM0gj6x98Bf"
      },
      "source": [
        "### 2.2. Cloning project from github\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "This is to clone the entire repo from github. Please do not execute this unless you want to clone the entire environment from github again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAxD_xM98SxW",
        "outputId": "6f8bacc7-ed25-4b7f-d79c-cd6acf1f7b8f"
      },
      "source": [
        "# import os\r\n",
        "# from getpass import getpass\r\n",
        "# import urllib\r\n",
        "\r\n",
        "# user = input('User name: ')\r\n",
        "# password = getpass('Password: ')\r\n",
        "# password = urllib.parse.quote(password) # your password is converted into url format\r\n",
        "# repo_name = input('Repo name: ')\r\n",
        "\r\n",
        "# cmd_string = 'git clone https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\r\n",
        "\r\n",
        "# os.system(cmd_string)\r\n",
        "# cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: ngzhankang\n",
            "Password: ··········\n",
            "Repo name: Deep-Learning_ca2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYmr-Hvc-KUx"
      },
      "source": [
        "# 3.Background Information"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbxYoVTx-L2V"
      },
      "source": [
        "### 3.1.About The CelebA Dataset\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyzIe5W--M_W"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3K1v5f0-Oef"
      },
      "source": [
        "### 3.2.CelebA Dataset\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fn-8N1O-PFg"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlODSB4R-QQf"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcN_jgr0-TDg"
      },
      "source": [
        "# 4.Data Importing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aZK6nNh-Uos"
      },
      "source": [
        "### 4.1.Load the libraries\r\n",
        "---\r\n",
        "Load the necessary libraries for usage in the entire project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPLYTWRD-Kk9"
      },
      "source": [
        "# Suppress Future Warnings\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6D3r-jI-WFe"
      },
      "source": [
        "# check versions of libraries we are going to use\r\n",
        "%tensorflow_version 2.x\r\n",
        "import os\r\n",
        "import tensorflow\r\n",
        "import sklearn\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib\r\n",
        "import platform\r\n",
        "\r\n",
        "message=\"        Versions        \"\r\n",
        "print(\"*\"*len(message))\r\n",
        "print(message)\r\n",
        "print(\"*\"*len(message))\r\n",
        "print(\"Tensorflow version={}\".format(tensorflow.__version__))\r\n",
        "print(\"Keras version={}\".format(tensorflow.keras.__version__))\r\n",
        "print(\"Sklearn version={}\".format(sklearn.__version__))\r\n",
        "print(\"Numpy version={}\".format(np.__version__))\r\n",
        "print(\"Pandas version={}\".format(pd.__version__))\r\n",
        "print(\"Seaborn version={}\".format(sns.__version__))\r\n",
        "print(\"Matplotlib version={}\".format(matplotlib.__version__))\r\n",
        "print(\"Python version={}\".format(platform.python_version()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Su4VLzfu-YCJ"
      },
      "source": [
        "# download the necessary libraries that is not inside keras library\r\n",
        "\r\n",
        "# start importing necessary libraries\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.models import Sequential, load_model\r\n",
        "from tensorflow.keras.layers import Dense, Reshape, Dropout   \r\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, BatchNormalization\r\n",
        "from tensorflow.keras.layers import LeakyReLU\r\n",
        "from tensorflow.keras.layers import AveragePooling2D, MaxPooling2D\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "\r\n",
        "# for making graphcial progress bar\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "# for adding support to different image file type\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H_KYprj-ZdP"
      },
      "source": [
        "# get the links of the dataset that i have stored in my github repo\r\n",
        "list_attr_celeba_csv_url = 'https://raw.githubusercontent.com/ngzhankang/Deep-Learning_ca2/main/dataset/list_attr_celeba.csv?token=APIZFPVQ6Z5UI3YC5FE4EU275CHRQ'\r\n",
        "list_bbox_celeba_csv_url = 'https://raw.githubusercontent.com/ngzhankang/Deep-Learning_ca2/main/dataset/list_bbox_celeba.csv?token=APIZFPWJZ7ZWPUKX4WYPGOS75CHT2'\r\n",
        "list_eval_partition_csv_url = 'https://raw.githubusercontent.com/ngzhankang/Deep-Learning_ca2/main/dataset/list_eval_partition.csv?token=APIZFPQFHFR2ROVXSXNNLYK75CHVY'\r\n",
        "list_landmarks_align_celeba_csv_url = 'https://raw.githubusercontent.com/ngzhankang/Deep-Learning_ca2/main/dataset/list_landmarks_align_celeba.csv?token=APIZFPQ27MDPHJZ4HABUPVS75CHX2'\r\n",
        "\r\n",
        "# now using the links we load into panda dataframes\r\n",
        "list_attr_celeba_csv = pd.read_csv(list_attr_celeba_csv_url, delimiter=',')\r\n",
        "list_bbox_celeba_csv = pd.read_csv(list_bbox_celeba_csv_url, delimiter=',')\r\n",
        "list_eval_partition_csv = pd.read_csv(list_eval_partition_csv_url, delimiter=',')\r\n",
        "list_landmarks_align_celeba_csv = pd.read_csv(list_landmarks_align_celeba_csv_url, delimiter=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gan8z9Uu-cSM"
      },
      "source": [
        "### 4.2.Creating `hms_string` class for time recording purposes\r\n",
        "---\r\n",
        "We create `hms_string` class for time recording purposes later on when we train our models, so that we can see the time elapsed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JnemQ3_-bhj"
      },
      "source": [
        "# Nicely formatted time string\r\n",
        "def hms_string(sec_elapsed):\r\n",
        "    h = int(sec_elapsed / (60 * 60))\r\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\r\n",
        "    s = sec_elapsed % 60\r\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dDYSXoI-eIN"
      },
      "source": [
        "---\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5eOAPrc-gRI"
      },
      "source": [
        "# 5.Exporatory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhwS96xG-iAL"
      },
      "source": [
        "### 5.1.Basic Data Exploration\r\n",
        "---\r\n",
        "Take a peek look at what is inside the respective dataframes first before we do something to it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I703Z8oY-5gO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}