{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOeeR6+Qog2WYwD4h4WMm+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngzhankang/Deep-Learning/blob/main/Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgTaLrOvB90e"
      },
      "source": [
        "# Assignment 1\n",
        "Submitted by : P1935727 Ng Zhan Kang<br>\n",
        "Class of DIT/FT/2B/11\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc_pUkkFF9Lg"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vE-S0J3BG-jO"
      },
      "source": [
        "# 1.Setting Up Working Environment In Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEaQJ7Rz88NW"
      },
      "source": [
        "### 1.1 Ensuring 0% Util\n",
        "\n",
        "---\n",
        "\n",
        "Ensure that our slot give by Google is not utilized yet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vU3IPB-9wF6",
        "outputId": "d7d7122c-a361-47a6-eee0-ff9c4b33307f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# to ensure that the current gpu utilization is 0\n",
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Gen RAM Free: 12.8 GB  | Proc size: 111.5 MB\n",
            "GPU RAM Free: 16280MB | Used: 0MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWjAy1ds9Kns"
      },
      "source": [
        "### 1.2. Forcing Utils To 0%\n",
        "\n",
        "---\n",
        "\n",
        "Please do not use this step unless forced to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gqa73iPB93yZ"
      },
      "source": [
        "# if utilization is > 0, run this code(keep running this cell and the above cell till the util number is 0%):\n",
        "# NOTE THAT RUNNING THIS MIGHT KILL GPU SESSION AND RESULT IN DATA LOSS(NOT ADVICABLE TO KEEP ON REUSING)\n",
        "# !kill -9 -1"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0aYmZCq8qjQ"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfVnMSOFGln8"
      },
      "source": [
        "# 2.Ensuring GPU Is Utilized In Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbDAAbwSG7DN"
      },
      "source": [
        "### 2.1. See the list of available devices\n",
        "\n",
        "---\n",
        "\n",
        "This entire section can be omitted if users are not utilizing GPU at all."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6OEWFOMcAM_",
        "outputId": "0c8656da-1c84-4aca-e5c5-784e527cb359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13823992593588731936\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 11050842002658409210\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 10486982132364812906\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 15695118336\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 7506573143275270435\n",
            "physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baot31IdcLjO",
        "outputId": "9ebeea6c-767f-4984-e4a1-401e9bd929ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS-gWw_jcOeh",
        "outputId": "6c44aafb-ac2e-460b-ca14-cdbfcd72015b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.test.gpu_device_name()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F08LAekAHBhq"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id1KUxFrCnKw"
      },
      "source": [
        "# 3.About The MNIST Dataset (Background Information)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QiQ-Uvol8ZIp"
      },
      "source": [
        "## 3.1. Background\n",
        "- The MNIST database(Modified National Institute of Standards and Technology database) history came to existence by \n",
        "- The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRAg_XY2CsJ3"
      },
      "source": [
        "## 3.2. Classic MNIST Dataset\n",
        "- For this problem, create a CNN for image classification and evaluate the performance of the network\n",
        "- Prepare the data and perform necessary feature engineering\n",
        "- Create **_three models_** \n",
        "- Evaluate the models and pick the best candidate\n",
        "- Form some conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSnt3olNIJlH"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-AF7n6VCwiI"
      },
      "source": [
        "# 4.Data Importing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xGz4pqKINfL"
      },
      "source": [
        "### 4.1. Load the libraries\n",
        "\n",
        "---\n",
        "\n",
        "Import the necessary libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4GavKz7CzgA"
      },
      "source": [
        "# Suppress Future Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OMhNQRPC23r",
        "outputId": "b9ed14de-dee1-45f2-86e4-b96f753663ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install keras-tuner\n",
        "# check versions of libraries we are going to use\n",
        "%tensorflow_version 2.x\n",
        "import os\n",
        "import tensorflow\n",
        "import kerastuner\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import platform\n",
        "\n",
        "message=\"        Versions        \"\n",
        "print(\"*\"*len(message))\n",
        "print(message)\n",
        "print(\"*\"*len(message))\n",
        "print(\"Tensorflow version={}\".format(tensorflow.__version__))\n",
        "print(\"KerasTuner version={}\".format(kerastuner.__version__))\n",
        "print(\"Numpy version={}\".format(np.__version__))\n",
        "print(\"Pandas version={}\".format(pd.__version__))\n",
        "print(\"Seaborn version={}\".format(sns.__version__))\n",
        "print(\"Matplotlib version={}\".format(matplotlib.__version__))\n",
        "print(\"Python version={}\".format(platform.python_version()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.4.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.18.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.6.20)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (0.17.0)\n",
            "************************\n",
            "        Versions        \n",
            "************************\n",
            "Tensorflow version=2.3.0\n",
            "KerasTuner version=1.0.1\n",
            "Numpy version=1.18.5\n",
            "Pandas version=1.1.4\n",
            "Seaborn version=0.11.0\n",
            "Matplotlib version=3.2.2\n",
            "Python version=3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjLekX4z9_nf"
      },
      "source": [
        "# start importing necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Activation, BatchNormalization\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping\n",
        "from kerastuner import HyperModel\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXWoWulRC_sP"
      },
      "source": [
        "# get the dataset from keras library in tensorflow 2.0\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "# unpack the dataset to the respective x_train, y_train, x_test and y_test\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYcgK0sTFrvZ"
      },
      "source": [
        "### 4.2. Verify the dataset\n",
        "\n",
        "---\n",
        "\n",
        "Verify the credibility of the dataset first by plotting the 1st 25 images from the training set and display the class name below each image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXCBHJQVFsGK",
        "outputId": "b8f6b8a3-415d-4cb1-b342-a9a483f95f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "numbers = ['0','1','2','3','4','5','6','7','8','9']\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(numbers[y_train[i]], color=\"yellow\")\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6lG2VSFF7nC"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "    <b>Analysis Summary:</b> It seems that the labels matches all the images, which is good! Now let's carry on to get a better insight of the datatset we are going to deal with.<p>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARlNpLenHMk-"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34w33z5aHNrb"
      },
      "source": [
        "# 5.Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gkd8sWV_6oht"
      },
      "source": [
        "### 5.1. Basic Data Exploration\n",
        "\n",
        "---\n",
        "\n",
        "Take a peek look at what is inside the `x_train` and the `x_test`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5xOZA3G4HYf",
        "outputId": "a945849f-baa6-42bc-a42e-a05973dd711e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# take a look at the x_train set first\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR9JVfvk62fU",
        "outputId": "c1b94ac3-30d7-43e2-fa55-7251c0dda1f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# take a look at the x_test set\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR66TbQJ6-An",
        "outputId": "a8aa1d69-5288-4a80-b427-c275339ddd96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# grab a random picture to take a look\n",
        "plt.imshow(x_train[5], cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQeHiDS47ZVw",
        "outputId": "7a367c6a-1f4c-4878-ab65-2285206f269b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get the distinct lables that are found in the entire thing\n",
        "print('Training set unique labels:',np.unique(y_train))\n",
        "print('Test set unique labels:',np.unique(y_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set unique labels: [0 1 2 3 4 5 6 7 8 9]\n",
            "Test set unique labels: [0 1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s94V4iGA6IgO",
        "outputId": "a74ead35-dca7-4669-a9f7-6411f063290b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get the count of the values from 0 to 9\n",
        "unique, counts = np.unique(y_train, return_counts=True)\n",
        "print(np.asarray((unique, counts)).T)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0 5923]\n",
            " [   1 6742]\n",
            " [   2 5958]\n",
            " [   3 6131]\n",
            " [   4 5842]\n",
            " [   5 5421]\n",
            " [   6 5918]\n",
            " [   7 6265]\n",
            " [   8 5851]\n",
            " [   9 5949]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPO-4wQGHnq-"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e7cOjDtHrpd"
      },
      "source": [
        "# 6.Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpE9BpXTIbsN"
      },
      "source": [
        "### 6.1. Changing Dimension To Match Keras Expectation\n",
        "\n",
        "---\n",
        "\n",
        "Reshape `x_train` and `x_test` to 4 dimensional array for the convolutional layer later on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrcpIcCiIF6k",
        "outputId": "0420de33-8052-4885-9c3f-07a717eb24ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# see the shape of x_train and x_test first\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUNk_StCNAN-"
      },
      "source": [
        "# flatten 28*28 images to a 784 vector for each image\n",
        "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
        "x_train = x_train.reshape(x_train.shape[0], num_pixels).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], num_pixels).astype('float32')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdhRaVB9Ifje",
        "outputId": "2ffcbce3-6c01-4582-db35-6da44ebc707b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# see the changes\n",
        "print('New x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New x_train shape: (60000, 784)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6PR8lUGIjf7"
      },
      "source": [
        "### 6.2. Normalize Training Data\n",
        "\n",
        "---\n",
        "\n",
        "Normalize the entire training dataset so that there is not much variation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxgG6lH8Igxn"
      },
      "source": [
        "# attempt to normalize the entire dataset first from 0-255 to 0-1\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hejHzHbJJslI"
      },
      "source": [
        "### 6.3. Convert To Categorical Data\n",
        "\n",
        "---\n",
        "\n",
        "Convert the labels to categorical data as we do not want the model to think 9 has a higher priority than 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxob5JCdJpem",
        "outputId": "7972ec18-ca7d-4069-88e9-8a8bdf19ab73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# see what does actually 1 label for the training dataset looks like in a numpy array\n",
        "# get the one from the 1st image\n",
        "print(y_train[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK0AsKgsJvcw",
        "outputId": "84e8a598-5412-4f15-ba28-0d1152700c3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# see what does actually 1 label for the test dataset looks like in a numpy array\n",
        "# get the one from the 1st image\n",
        "print(y_test[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdB5ywKlJwZs"
      },
      "source": [
        "# use to_categorical to convert the training and testing dataset labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58s_zZ4hJxne",
        "outputId": "d05e1e25-0360-4d62-e962-b2c1421cf9c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# now lets check again the training dataset labels\n",
        "print(y_train[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BZ0M7vUJyqW",
        "outputId": "ca1fafa2-145f-4320-de71-3fdea9551caf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# now lets check again the testing dataset labels\n",
        "print(y_test[0])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcOBYRkW35kT"
      },
      "source": [
        "### 6.4. Model Configuration\n",
        "\n",
        "---\n",
        "\n",
        "Set the configuration for our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sDxrErd3_us"
      },
      "source": [
        "# fix random seed so that we do not see variation in accuracy each time we run thru \n",
        "seed_value = 88\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "num_classes = y_test.shape[1] # number of classes (numbers 0 to 9)\n",
        "\n",
        "batch_size = 250 # batch size set to 250, which balances well between gradient preciseness and memory requirements."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBvx1V2rJ0pt"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCdKpcVDJ2uP"
      },
      "source": [
        "# 7.Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zSE3k8H-J43K"
      },
      "source": [
        "### 7.1. Baseline Model\n",
        "\n",
        "---\n",
        "\n",
        "First, we will setup a baseline model first using Keras Sequential Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5ZgkP_2Jzp0"
      },
      "source": [
        "# create model and give it a name\n",
        "model = Sequential(name=\"baseline_model_sequential\")\n",
        "\n",
        "# add 1st fully connected layer (hidden layer)\n",
        "model.add(Dense(num_pixels, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n",
        "\n",
        "# add 2nd fully connected layer (hidden layer)\n",
        "model.add(Dense(256,  kernel_initializer='normal', activation=tf.nn.relu))\n",
        "\n",
        "# add 3rd fully connected layer (hidden layer)\n",
        "model.add(Dense(128,  kernel_initializer='normal', activation=tf.nn.relu))\n",
        "model.add(Dropout(0.5)) # add a dropout layer to drop out some neurons during training to prevent overfitting\n",
        "\n",
        "# add output layer\n",
        "model.add(Dense(num_classes, kernel_initializer='normal', activation=tf.nn.softmax))\n",
        "\n",
        "# model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEf6RDMSSQUU"
      },
      "source": [
        "# time to optimise the empty baseline model(an empty shell basically) and fit it with our training dataset\n",
        "# passing params into the newly created model and compile it\n",
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "history = model.fit(x_train, y_train, validation_split=0.2, epochs=15, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7mw9nVaSpnz"
      },
      "source": [
        "#print the available history keys for use\n",
        "print(history.history.keys()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bB9_0TEVuD5"
      },
      "source": [
        "# plot a accuracy and validation loss graph to see the training and validation loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oerF-J2eWMON"
      },
      "source": [
        "# plot a accuracy and validation accuracy graph to see the training and validation accuracy at each epoch\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "plt.plot(epochs, accuracy, 'y', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xco3EGc2WPTi"
      },
      "source": [
        "### 7.2. CNN Model\n",
        "\n",
        "---\n",
        "\n",
        "Next, we will setup a CNN Model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5yWrRR7Obm3"
      },
      "source": [
        "# create model and give it a name\n",
        "model = Sequential(name=\"cnn_model_sequential\")\n",
        "\n",
        "# add 1st convolutional layer\n",
        "input_shape = (28, 28, 1) # declare input_shape as this is the 1st layer\n",
        "model.add(Conv2D(32, kernel_size=(3,3), input_shape=input_shape, kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(MaxPooling2D((2,2))) # add in a maxpooling 2d layer to reduce conputational complexity and overfitting\n",
        "          \n",
        "# add 2nd convolutional layer\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D((2,2))) # add in a maxpooling 2d layer to reduce conputational complexity and overfitting       \n",
        "          \n",
        "# add flatten layer\n",
        "model.add(Flatten()) # flatten prev 2d layer output to extract source from image for fully connected layers\n",
        "\n",
        "# add 1st fully connected layer (hidden layer)\n",
        "model.add(Dense(128))\n",
        "model.add(Dropout(0.5)) # add a dropout layer to drop out some neurons during training to prevent overfitting\n",
        "model.add(Activation('relu')) #dropout before activation function in fully connnect layers\n",
        "\n",
        "# add 2nd fully connected layer (hidden layer)\n",
        "model.add(Dense(50))\n",
        "model.add(Dropout(0.5)) # add a dropout layer to drop out some neurons during training to prevent overfitting\n",
        "model.add(Activation('relu')) #dropout before activation function in fully connnect layers\n",
        "          \n",
        "# add output layer\n",
        "model.add(Dense(num_classes, activation=tf.nn.softmax)) # output layer(10 neurons as we only have 10 numbers(0 to 9))       \n",
        "          \n",
        "# get model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLLKlKi-ewsG"
      },
      "source": [
        "# reshape x_train and x_test to (n_images, x_shape, y_shape, channels)\n",
        "# we are going to make chanels be 1 as we are not dealing with rgb images.\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# examine the shape before we feed it in\n",
        "print('New x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OpTrZNAeqK4"
      },
      "source": [
        "# time to optimise the empty CNN model(an empty shell basically) and fit it with our training dataset\n",
        "# passing params into the newly created model and compile it\n",
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "# train the model\n",
        "history = model.fit(x_train,y_train, validation_split=0.2, epochs=15, verbose=1, callbacks=[EarlyStopping(monitor='loss', patience=2)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z8RTDNDfwLs"
      },
      "source": [
        "#print the available history keys for use\n",
        "print(history.history.keys()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aT0rv8Tf0WC"
      },
      "source": [
        "# plot a accuracy and validation loss graph to see the training and validation loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSJNdv7nf3QY"
      },
      "source": [
        "# plot a accuracy and validation accuracy graph to see the training and validation accuracy at each epoch\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "plt.plot(epochs, accuracy, 'y', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbCUBdNt1yZ-"
      },
      "source": [
        "### 7.3. CNN Hyper-Parameter Tuned Model\n",
        "\n",
        "---\n",
        "\n",
        "Next, we will setup a CNN Model that has undergone hyper-parameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar0yEkv9Q6pG",
        "outputId": "ddccfdee-5312-40af-d831-3484be3fa232",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# reshape x_train and x_test to (n_images, x_shape, y_shape, channels)\n",
        "# we are going to make chanels be 1 as we are not dealing with rgb images.\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
        "\n",
        "# examine the shape before we feed it in\n",
        "print('New x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6zJGUXYXSJM"
      },
      "source": [
        "# perform hyper parameter tuning first\n",
        "\n",
        "# create model and give it a name\n",
        "model = Sequential(name=\"cnn_model_hyperParamTuned_sequential\")\n",
        "\n",
        "# add 1st convolutional layer\n",
        "input_shape = (28, 28, 1) # declare input_shape as this is the 1st layer\n",
        "model.add(Conv2D(hp.Int('units', min_value=32, max_value=512, step=32), kernel_size=(3,3), input_shape=input_shape, kernel_initializer='he_uniform', activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2))) # add in a maxpooling 2d layer to reduce conputational complexity and overfitting\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# add 2nd convolutional layer\n",
        "model.add(Conv2D(hp.Int('units', min_value=32, max_value=512, step=32), kernel_size=3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2))) # add in a maxpooling 2d layer to reduce conputational complexity and overfitting \n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# add 3rd convolutional layer\n",
        "model.add(Conv2D(hp.Int('units', min_value=32, max_value=512, step=32), kernel_size=3, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2))) # add in a maxpooling 2d layer to reduce conputational complexity and overfitting\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# add flatten layer\n",
        "model.add(Flatten()) # flatten prev 2d layer output to extract source from image for fully connected layers\n",
        "\n",
        "# add 1st fully connected layer (hidden layer)\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(rate=hp.Float('dropout_3', min_value=0.0, max_value=0.5, default=0.25, step=0.05))) # add a dropout layer to drop out some neurons during training to prevent overfitting\n",
        "model.add(Activation('relu')) #dropout before activation function in fully connnect layers\n",
        "\n",
        "# add 2nd fully connected layer (hidden layer)\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(rate=hp.Float('dropout_3', min_value=0.0, max_value=0.5, default=0.25, step=0.05))) # add a dropout layer to drop out some neurons during training to prevent overfitting\n",
        "model.add(Activation('relu')) #dropout before activation function in fully connnect layers\n",
        "\n",
        "# add output layer\n",
        "model.add(Dense(num_classes, activation=tf.nn.softmax)) # output layer(10 neurons as we only have 10 numbers(0 to 9)) \n",
        "\n",
        "# get the summary of the model\n",
        "model.summary()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxUF2VfW81Bc"
      },
      "source": [
        "# passing params into the newly created model and compile it\n",
        "  model.compile(optimizer='adam',\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=['accuracy'])\n",
        "  \n",
        "# train the model\n",
        "history = model.fit(x_train,y_train, validation_split=0.2, batch_size=num_pixels, epochs=15, verbose=1, callbacks=[EarlyStopping(monitor='loss', patience=1)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYcZQ3UOcZca"
      },
      "source": [
        "#print the available history keys for use\n",
        "print(history.history.keys()) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU5LfONxeKWI"
      },
      "source": [
        "# plot a accuracy and validation loss graph to see the training and validation loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'y', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFIuI75dgRWP"
      },
      "source": [
        "# plot a accuracy and validation accuracy graph to see the training and validation accuracy at each epoch\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "plt.plot(epochs, accuracy, 'y', label='Training Accuracy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation Accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il5MVQPrXIGb"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjU3M0fUWcX5"
      },
      "source": [
        "# 8.Test Accuracy, Loss And Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd6G1OH4WhAv"
      },
      "source": [
        "### 8.1. Baseline Model Result\n",
        "\n",
        "---\n",
        "\n",
        "Get the result for the baseline model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnmmCdUzWdsk"
      },
      "source": [
        "# now we shall evaluate the model and see the accuracy\n",
        "score = model.evaluate(x_test,y_test, verbose=1)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "print(\"BaseLine Model Error: %.2f%%\" % (100-score[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRjW__19ZQGK"
      },
      "source": [
        "# get a random index which we will use it to see what number it is from the test dataset(it shld be a number all the way to 60,000)\n",
        "image_index = 8\n",
        "\n",
        "# see what image it is first\n",
        "plt.imshow(x_test[image_index].reshape(28, 28),cmap=plt.cm.binary) # visually, we identify the number as 6\n",
        "# see the actual label\n",
        "actual_label = (y_test[image_index])\n",
        "print('Actual Label:', actual_label)\n",
        "\n",
        "# now lets try to feed the image_index into x_test and feed it into the trained model\n",
        "pred = model.predict(x_test[image_index].reshape(1,-1)) # changing it to a 1d array first\n",
        "print('Predicted Number:', pred.argmax()) # print out the result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMwQ_4HMeoLN"
      },
      "source": [
        "### 8.2. CNN Model Result\n",
        "\n",
        "---\n",
        "\n",
        "Get the result for the CNN model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGcNmEGEf8I0"
      },
      "source": [
        "# now we shall evaluate the model and see the accuracy\n",
        "score = model.evaluate(x_test,y_test)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])\n",
        "print(\"CNN Model Error: %.2f%%\" % (100-score[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tXbqxbpgETQ"
      },
      "source": [
        "# from the above result, we can see that we got an accuracy of 96.7% and a loss of 10.7%, which is not bad but can be better improved.\n",
        "# now we shall try to make individual predictions.\n",
        "\n",
        "# get a random index which we will use it to see what number it is from the test dataset(it shld be a number all the way to 60,000)\n",
        "image_index = 8\n",
        "\n",
        "# see what image it is first\n",
        "plt.imshow(x_test[image_index].reshape(28, 28),cmap=plt.cm.binary) # visually, we identify the number as 6\n",
        "# see the actual label\n",
        "actual_label = (y_test[image_index])\n",
        "print('Actual Label:', actual_label)\n",
        "\n",
        "# now lets try to feed the image_index into x_test and feed it into the trained model\n",
        "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
        "print('Predicted Number:', pred.argmax()) # print out the result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU45DXEOf2dz"
      },
      "source": [
        "### 8.3. CNN Hyper-Parameter Tuned Model Result\n",
        "\n",
        "---\n",
        "\n",
        "Get the result for the CNN model that has undergone hyper parameter tuning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShTJVSrtf8LD",
        "outputId": "124170f8-57f1-4678-867b-425a3a746359",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# now we shall evaluate the model and see the accuracy\n",
        "loss, accuracy = model3.evaluate(x_test,y_test)\n",
        "print(\"Test loss:\", loss)\n",
        "print(\"Test accuracy:\", accuracy)\n",
        "print(\"CNN Model Error: %.2f%%\" % (100-accuracy*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 2s 5ms/step - loss: 0.0584 - accuracy: 0.9876\n",
            "Test loss: 0.05835125595331192\n",
            "Test accuracy: 0.9876000285148621\n",
            "CNN Model Error: 1.24%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBMA3CS-f_TQ",
        "outputId": "880ac488-9f9e-46ae-9975-ae47482e84cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# from the above result, we can see that we got an accuracy of 96.7% and a loss of 10.7%, which is not bad but can be better improved.\n",
        "# now we shall try to make individual predictions.\n",
        "\n",
        "# get a random index which we will use it to see what number it is from the test dataset(it shld be a number all the way to 60,000)\n",
        "image_index = 8\n",
        "\n",
        "# see what image it is first\n",
        "plt.imshow(x_test[image_index].reshape(28, 28),cmap=plt.cm.binary) # visually, we identify the number as 6\n",
        "# see the actual label\n",
        "actual_label = (y_test[image_index])\n",
        "print('Actual Label:', actual_label)\n",
        "\n",
        "# now lets try to feed the image_index into x_test and feed it into the trained model\n",
        "pred = model3.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
        "print('Predicted Number:', pred.argmax()) # print out the result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Label: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "Predicted Number: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PIPpo7sbNRE"
      },
      "source": [
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fuJ322WcbQBu"
      },
      "source": [
        "# 9.References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WQh8SimbTVS"
      },
      "source": [
        "## Using Google Colab More Efficiently\n",
        "- [Getting the Most Out of Your Google Colab (Tutorial)](https://medium.com/@oribarel/getting-the-most-out-of-your-google-colab-2b0585f82403)\n",
        "- [Using Google Colab with GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "\n",
        "## Background Research\n",
        "\n",
        "## Selecting CNN Architecture\n",
        "- [Top 10 CNN Architecture](https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d#676b)\n",
        "- [AlexNet: The Architecture that Challenged CNNs](https://towardsdatascience.com/alexnet-the-architecture-that-challenged-cnns-e406d5297951)\n",
        "- [How to choose CNN Architecture MNIST](https://www.kaggle.com/cdeotte/how-to-choose-cnn-architecture-mnist#What-is-the-best-CNN-architecture-for-MNIST?)\n",
        "\n",
        "## Some Tutorials on how to build a CNN Model\n",
        "- [Building a Custom Convolutional Neural Network in Keras](https://medium.com/@ODSC/building-a-custom-convolutional-neural-network-in-keras-48171163aa7f)\n",
        "- [The Most Intuitive and Easiest Guide for Convolutional Neural Network](https://towardsdatascience.com/the-most-intuitive-and-easiest-guide-for-convolutional-neural-network-3607be47480)\n",
        "- [MNIST with Keras for Beginners(.99457)](https://www.kaggle.com/adityaecdrid/mnist-with-keras-for-beginners-99457)\n",
        "- [Image Classification in 10 Minutes with MNIST Dataset](https://towardsdatascience.com/image-classification-in-10-minutes-with-mnist-dataset-54c35b77a38d)\n",
        "- [How to Develop a CNN for MNIST Handwritten Digit Classification](https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-from-scratch-for-mnist-handwritten-digit-classification/#:~:text=The%20MNIST%20dataset%20is%20an,digits%20between%200%20and%209.)\n",
        "\n",
        "## Feature Engineering\n",
        "- [Why Change Data Dimension Before Feeding Into Keras?](https://stackoverflow.com/a/62991238/12347869)\n",
        "- [Properly Setting the Random Seed in ML Experiments. Not as Simple as You Might Imagine](https://medium.com/@ODSC/properly-setting-the-random-seed-in-ml-experiments-not-as-simple-as-you-might-imagine-219969c84752)\n",
        "- [How to get reproducible results in keras](https://stackoverflow.com/questions/32419510/how-to-get-reproducible-results-in-keras)\n",
        "- [How can I obtain reproducible results using Keras during development?](https://keras.io/getting_started/faq/#how-can-i-obtain-reproducible-results-using-keras-during-development)\n",
        "\n",
        "## Building Layers\n",
        "- [What is the default weight initializer in Keras?](https://stackoverflow.com/questions/54011173/what-is-the-default-weight-initializer-in-keras)\n",
        "- [A Gentle Introduction to Pooling Layers for Convolutional Neural Networks](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/)\n",
        "- [Using the Keras Flatten Operation in CNN Models with Code Examples](https://missinglink.ai/guides/keras/using-keras-flatten-operation-cnn-models-code-examples/)\n",
        "- [Dropout Neural Network Layer In Keras Explained](https://towardsdatascience.com/machine-learning-part-20-dropout-keras-layers-explained-8c9f6dc4c9ab)\n",
        "- [Changing shape of MNIST for tensorflow CNN](https://stackoverflow.com/questions/50549859/changing-shape-of-mnist-for-tensorflow-cnn)\n",
        "\n",
        "## Model Evaluation \n",
        "- [Sparse_categorical_crossentropy vs categorical_crossentropy (keras, accuracy)](https://datascience.stackexchange.com/questions/41921/sparse-categorical-crossentropy-vs-categorical-crossentropy-keras-accuracy)\n",
        "\n",
        "## Hyper Parameter Tuning With Keras Tuner\n",
        "- [Hyperparameter tuning with Keras Tuner](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)\n",
        "- [Why is random search better than grid search for machine learning?](https://analyticsindiamag.com/why-is-random-search-better-than-grid-search-for-machine-learning/#:~:text=Random%20search%20is%20a%20technique,to%20yield%20better%20results%20comparatively.)\n",
        "- [Hands on hyperparameter tuning with Keras Tuner](https://www.sicara.ai/blog/hyperparameter-tuning-keras-tuner)\n",
        "- [Keras Tuner Docs](https://keras-team.github.io/keras-tuner/)\n",
        "- [How do you decide the parameters of a Convolutional Neural Network for image classification?](https://stackoverflow.com/questions/24509921/how-do-you-decide-the-parameters-of-a-convolutional-neural-network-for-image-cla#:~:text=The%20Number%20of%20convolutional%20layers,you%20need%20to%20decide%20whether)\n"
      ]
    }
  ]
}